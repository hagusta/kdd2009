{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, time, math\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras import layers,losses,metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle','rb') as f:\n",
    "    data=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=pd.concat([data['train_num'],data['train_cat']],axis=1)\n",
    "#x_test=pd.concat([data['test_num'],data['test_cat']],axis=1)\n",
    "#x_train=pd.concat([data['train_norm'],data['train_tbs']],axis=1)\n",
    "#x_test=pd.concat([data['test_norm'],data['test_tbs']],axis=1)\n",
    "x_train=pd.concat([data['train_norm'],data['train_tbs']],axis=1)\n",
    "x_test=pd.concat([data['test_norm'],data['test_tbs']],axis=1)\n",
    "y_train=data['y_train']\n",
    "y_test=data['y_test']\n",
    "column_names=x_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_train=x_train.reindex(sorted(x_train.columns),axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def split_pair(x,y,n_splits=5,klas=1):\n",
    "    #global col_cat\n",
    "    split_pair=[]\n",
    "    split=StratifiedKFold(n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "    for train_idx, test_idx in split.split(x,y):\n",
    "        xtrain=x.iloc[train_idx]\n",
    "        ytrain=y.iloc[train_idx]\n",
    "        xtest=x.iloc[test_idx]\n",
    "        ytest=y.iloc[test_idx]\n",
    "\n",
    "        split_pair.append([(xtrain,ytrain),(xtest,ytest)])\n",
    "\n",
    "    return split_pair"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv_pair=split_pair(x_train,y_train,n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x_train).astype('float32')\n",
    "x_test=np.array(x_test).astype('float32')\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "#data=None"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def confusion_mat(y_test,y_pred):\n",
    "    true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_test,y_pred).ravel()\n",
    "    print(\"Actual\\t\\t|  Pos     |   Neg    |\")\n",
    "    print(\"Predicted\\t-----------------\")\n",
    "    print(\"Pos\\t\\t| {0:08d} | {1:08d} |\".format(true_positive,false_positive))\n",
    "    print(\"Neg\\t\\t| {0:08d} | {1:08d} |\\n\".format(false_negative,true_negative))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostOpt(Callback):\n",
    "    \n",
    "    def __init__(self, x_train, y_train, x_test, y_test):\n",
    "        #self.model = model\n",
    "\n",
    "        self.epoch = []\n",
    "        self.history = {}\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        #tf.reset_default_graph()\n",
    "        \n",
    "        st=time.time()\n",
    "        model=self.model\n",
    "        test_pred=model.predict_classes(self.x_test)\n",
    "        #test_au=auc(self.y_test,test_pred)\n",
    "        #test_au=auc_roc(self.y_test,test_pred)\n",
    "        #train_pred=model.predict_classes(self.x_train)\n",
    "        #train_au=auc(self.y_train,train_pred)\n",
    "        #train_au=auc_roc(self.y_train,train_pred)\n",
    "        _,test_au=tf.metrics.auc(self.y_test,test_pred)\n",
    "        #_,train_au=tf.metrics.auc(self.y_train,train_pred)\n",
    "        sess=tf.Session()\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        #a0,a1=sess.run([train_au,test_au])\n",
    "        a1=sess.run([test_au])\n",
    "        tm=time.time()-st\n",
    "        a0=0\n",
    "        #print(a1)\n",
    "        #print(\"Epoch {2:02d} Eval : {0:.4f} val_auc: {1:.4f} in {3:4.2f} sec\".format(a0,a1[,epoch,tm))\n",
    "        self.history.setdefault('chk_auc', []).append(a1)\n",
    "        print(a0,a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_unit=32):\n",
    "\n",
    "    input_feature_num=x_train.shape[1]\n",
    "    \n",
    "    model = Sequential(name=\"kdd2009\")\n",
    "    \n",
    "    \n",
    "    model.add(layers.BatchNormalization(name=\"Input_Norm\", input_shape=(input_feature_num,)))\n",
    "    #model.add(layers.Dropout(.7))\n",
    "    #model.add(layers)\n",
    "    \n",
    "    model.add(layers.Dense(name='hidden_l1', units=hidden_unit))\n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.BatchNormalization(name=\"Input_Norm2\"))\n",
    "    model.add(layers.Dense(name='hidden_l2', units=hidden_unit))\n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.BatchNormalization(name=\"Input_Norm3\"))         \n",
    "    model.add(layers.Dense(name='hidden_l3', units=hidden_unit))\n",
    "    #model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(name='output', units=1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def fit(x_train,y_train,x_test, y_test, run_time, fold_n, batch_size=2000,epochs=20):\n",
    "    model = None\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam',loss=losses.binary_crossentropy, metrics=['accuracy',auc])\n",
    "    filepath=run_time+\"/model-{fold_n:02d}-{epoch:02d}-{loss:.4f}\"\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    earlystop=EarlyStopping(monitor='loss', min_delta=1e-4, patience=5, verbose=0, mode='auto')\n",
    "    callbacks_list = [earlystop,SecondOpinion(model,x_train,y_train,x_test,y_test)]\n",
    "    history=model.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=epochs,\n",
    "              validation_data=(x_test,y_test),verbose=1,callbacks=callbacks_list)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "run_time=(datetime.now()).strftime('%Y%m%d%H%M')\n",
    "path=run_time\n",
    "if not os.path.isdir(path):\n",
    "    os.mkdir(path)\n",
    "result=dict()\n",
    "for i in range(len(cv_pair)):\n",
    "    print(\"fold\"+{i+1:02d})\n",
    "    xtrain=cv_pair[i][0][0]\n",
    "    ytrain=cv_pair[i][0][1]\n",
    "    xtest=cv_pair[i][1][0]\n",
    "    ytest=cv_pair[i][1][1]\n",
    "    history=fit(xtrain,ytrain,xtest,ytest,run_time,fold_n=i+1)\n",
    "    result.update({i+1:history})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_fold=5\n",
    "idx=np.where(y==1)[0]\n",
    "idxf=np.where(y!=1)[0]\n",
    "dt_t=np.concatenate((x[idx,:],y[idx,:]),axis=1)\n",
    "dt_f=np.concatenate((x[idxf,:],y[idxf,:]),axis=1)\n",
    "\n",
    "n_f=dt_f.shape[0]\n",
    "n_t=dt_t.shape[0]\n",
    "n_f_batch=int(n_f/n_fold)+1\n",
    "n_t_batch=int(n_t/n_fold)+1\n",
    "\n",
    "cnt=0\n",
    "i=0\n",
    "j=1\n",
    "col_n=dt_t.shape[1]-1\n",
    "while(j):\n",
    "    dt_batch=np.concatenate((dt_t[n_t_batch*(i):n_t_batch*(i+1)],dt_f[n_f_batch*i:n_f_batch*(i+1)]),axis=0)\n",
    "    #print(batch.shape)\n",
    "    np.random.shuffle(dt_batch)\n",
    "    x_batch=dt_batch[:,0:col_n-1]\n",
    "    y_batch=dt_batch[:,col_n]\n",
    "    print(x_batch.shape,y_batch.shape)\n",
    "    #batches.append(batch)\n",
    "    cnt=cnt+n_f_batch\n",
    "    i=i+1\n",
    "    if n_f < cnt:\n",
    "        i=0\n",
    "        j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    "\n",
    "def generator(x, y, batch_size):\n",
    "    #print(\"generator\")\n",
    "    idx_true = y[y==1]\n",
    "    idx_false = y[y!=1]\n",
    "    #sample_true=np.concatenate((x[idx_true,:],y_data[idx_true,:]),axis=1)\n",
    "    #sample_false=np.concatenate((x[idx_false,:],y_data[idx_false,:]),axis=1)\n",
    "    #print('positive:',idx_true.shape[0],' negative: ',idx_false.shape[0])\n",
    "    x_true=x[idx_true]\n",
    "    x_false=x[idx_false]\n",
    "    y_true=y[idx_true]\n",
    "    y_false=y[idx_false]\n",
    "\n",
    "    number_samples_true_per_epoch = idx_true.shape[0]\n",
    "    number_samples_false_per_epoch = idx_false.shape[0] \n",
    "    true_ratio=number_samples_true_per_epoch/(number_samples_false_per_epoch+number_samples_true_per_epoch)\n",
    "    #false_ratio\n",
    "    true_batches = int(math.ceil(batch_size*true_ratio))\n",
    "    false_batches = int(batch_size*(1-true_ratio))\n",
    "    number_of_batches=int(y.shape[0]/batch_size)\n",
    "    counter=0\n",
    "    #n_col=x.shape[1]\n",
    "    #print(true_batches,false_batches)\n",
    "    #print(\"\\nblah\")\n",
    "    while 1:\n",
    "    \n",
    "        #print(counter,true_batches*counter,true_batches*(counter+1),\n",
    "        #     false_batches*counter,false_batches*(counter+1),'\\n')\n",
    "        #,'number_of_true_batches',number_of_true_batches,'number_of_false_batches',number_of_false_batches,'\\n')\n",
    "        counter += 1\n",
    "        #print(\"\\n\",counter,false_batches*(counter-1),false_batches*(counter),\"\\n\")\n",
    "        if number_of_batches <= counter:\n",
    "                   \n",
    "            x_batch = np.concatenate((x_true[true_batches*(counter-1):],\n",
    "                                x_false[false_batches*(counter-1):])\n",
    "                               ,axis=0).astype('float32')\n",
    "\n",
    "            y_batch = np.concatenate((y_true[true_batches*(counter-1):],\n",
    "                                y_false[false_batches*(counter-1):])\n",
    "                               ,axis=0).astype('float32')\n",
    "            counter = 0 \n",
    "        else:\n",
    "            x_batch = np.concatenate((x_true[true_batches*(counter-1):true_batches*(counter)],\n",
    "                                x_false[false_batches*(counter-1):false_batches*(counter)])\n",
    "                               ,axis=0).astype('float32')\n",
    "\n",
    "            y_batch = np.concatenate((y_true[true_batches*(counter-1):true_batches*(counter)],\n",
    "                                y_false[false_batches*(counter-1):false_batches*(counter)])\n",
    "                               ,axis=0).astype('float32')            \n",
    "        \n",
    "        yield shuffle_in_unison(x_batch,y_batch)\n",
    "        \n",
    "def generator2(x, y, batch_size):\n",
    "    idx_true = y[y==1]\n",
    "    idx_false = y[y!=1]\n",
    "\n",
    "    x_true=x[idx_true]\n",
    "    #x_false=x[idx_false]\n",
    "    y_true=y[idx_true]\n",
    "    #y_false=y[idx_false]\n",
    "\n",
    "    number_samples_true_per_epoch = idx_true.shape[0]\n",
    "    number_samples_false_per_epoch = idx_false.shape[0] \n",
    "    true_ratio=number_samples_true_per_epoch/(number_samples_false_per_epoch+number_samples_true_per_epoch)\n",
    "    #false_ratio\n",
    "    #print('true ratio:',true_ratio)\n",
    "    true_batches = int(math.ceil(batch_size*true_ratio))\n",
    "    #false_batches = int(batch_size*(1-true_ratio))\n",
    "    number_of_batches=int(y.shape[0]/batch_size)\n",
    "    #print('number_of_batches:',number_of_batches)\n",
    "    counter=0\n",
    "    \n",
    "    while 1:\n",
    "        #print(counter)\n",
    "        counter += 1\n",
    "        idx=np.random.randint(0,y.shape[0]-1,[true_batches,])\n",
    "        #_idx=idx[0:]\n",
    "        #print(idx.shape)\n",
    "        if number_of_batches <= counter:\n",
    "            #print(\"2\",number_of_batches)\n",
    "            x_batch = np.concatenate((x_true[true_batches*(counter-1):true_batches*(counter)],\n",
    "                                x[idx])\n",
    "                               ,axis=0).astype('float32')\n",
    "\n",
    "            y_batch = np.concatenate((y_true[true_batches*(counter-1):true_batches*(counter)],\n",
    "                                y[idx])\n",
    "                               ,axis=0).astype('float32')\n",
    "            counter = 0 \n",
    "        else:\n",
    "            #print(\"1\",number_of_batches)\n",
    "            x_batch = np.concatenate((x_true[true_batches*(counter-1):true_batches*(counter)],\n",
    "                                x[idx])\n",
    "                               ,axis=0).astype('float32')\n",
    "\n",
    "            y_batch = np.concatenate((y_true[true_batches*(counter-1):true_batches*(counter)],\n",
    "                                y[idx])\n",
    "                               ,axis=0).astype('float32')            \n",
    "        #print(x_batch.shape)\n",
    "        yield shuffle_in_unison(x_batch,y_batch)\n",
    "        #yield x_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "model = None\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam',loss=losses.binary_crossentropy, metrics=['acc',auc])\n",
    "filepath=\"weights-auc\"\n",
    "earlystop=EarlyStopping(monitor='val_auc', min_delta=2e-4, patience=10, verbose=0, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "#callbacks_list = [earlystop,PostOpt(x_train,y_train,x_test,y_test),checkpoint]\n",
    "callbacks_list = [earlystop]\n",
    "#model.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=10,\n",
    "          #validation_data=(x_test,y_test),\n",
    "#          verbose=1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate_generator(generator=generator(x_train, y_train,batch_size),steps=2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 10s 219us/step - loss: 0.1280 - acc: 0.9736 - auc: 0.4942 - val_loss: 0.0893 - val_acc: 0.9822 - val_auc: 0.5018\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 8s 175us/step - loss: 0.1004 - acc: 0.9822 - auc: 0.4966 - val_loss: 0.0898 - val_acc: 0.9822 - val_auc: 0.4932\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 7s 159us/step - loss: 0.0974 - acc: 0.9822 - auc: 0.4941 - val_loss: 0.0899 - val_acc: 0.9822 - val_auc: 0.4946\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 8s 188us/step - loss: 0.0959 - acc: 0.9822 - auc: 0.4956 - val_loss: 0.0896 - val_acc: 0.9822 - val_auc: 0.4954\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 7s 152us/step - loss: 0.0946 - acc: 0.9822 - auc: 0.4968 - val_loss: 0.0902 - val_acc: 0.9822 - val_auc: 0.4952\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 7s 152us/step - loss: 0.0932 - acc: 0.9822 - auc: 0.4955 - val_loss: 0.0901 - val_acc: 0.9822 - val_auc: 0.4962\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 8s 173us/step - loss: 0.0928 - acc: 0.9822 - auc: 0.4963 - val_loss: 0.0895 - val_acc: 0.9822 - val_auc: 0.4971\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 7s 154us/step - loss: 0.0918 - acc: 0.9822 - auc: 0.4979 - val_loss: 0.0896 - val_acc: 0.9822 - val_auc: 0.4983\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0920 - acc: 0.9822 - auc: 0.4986 - val_loss: 0.0899 - val_acc: 0.9822 - val_auc: 0.4982\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 6s 144us/step - loss: 0.0912 - acc: 0.9822 - auc: 0.4985 - val_loss: 0.0899 - val_acc: 0.9822 - val_auc: 0.4992\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 6s 142us/step - loss: 0.0911 - acc: 0.9822 - auc: 0.4995 - val_loss: 0.0894 - val_acc: 0.9822 - val_auc: 0.4999\n"
     ]
    }
   ],
   "source": [
    "hist1=model.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=100,\n",
    "          validation_data=(x_test,y_test),\n",
    "          verbose=1,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "model2 = None\n",
    "model2 = create_model()\n",
    "model2.compile(optimizer='adam',loss=losses.binary_crossentropy, metrics=['acc',auc])\n",
    "filepath=\"weights-auc\"\n",
    "earlystop=EarlyStopping(monitor='acc', min_delta=1e-3, patience=10, verbose=0, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [earlystop,PostOpt(x_train,y_train,x_test,y_test),checkpoint]\n",
    "callbacks_list = [earlystop,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/703 [==============================] - 13s 18ms/step - loss: 0.1192 - acc: 0.9698 - auc: 0.4817 - val_loss: 0.1089 - val_acc: 0.9822 - val_auc: 0.4642\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.96712, saving model to weights-auc\n",
      "Epoch 2/100\n",
      "704/703 [==============================] - 10s 14ms/step - loss: 0.0753 - acc: 0.9870 - auc: 0.4685 - val_loss: 0.1054 - val_acc: 0.9820 - val_auc: 0.4733\n",
      "\n",
      "Epoch 00002: acc improved from 0.96712 to 0.98729, saving model to weights-auc\n",
      "Epoch 3/100\n",
      "704/703 [==============================] - 9s 12ms/step - loss: 0.0886 - acc: 0.9833 - auc: 0.4806 - val_loss: 0.1023 - val_acc: 0.9820 - val_auc: 0.4961\n",
      "\n",
      "Epoch 00003: acc did not improve from 0.98729\n",
      "Epoch 4/100\n",
      "704/703 [==============================] - 9s 12ms/step - loss: 0.0869 - acc: 0.9843 - auc: 0.5057 - val_loss: 0.1005 - val_acc: 0.9822 - val_auc: 0.5057\n",
      "\n",
      "Epoch 00004: acc did not improve from 0.98729\n",
      "Epoch 5/100\n",
      "704/703 [==============================] - 8s 12ms/step - loss: 0.0775 - acc: 0.9857 - auc: 0.5120 - val_loss: 0.1014 - val_acc: 0.9820 - val_auc: 0.5146\n",
      "\n",
      "Epoch 00005: acc did not improve from 0.98729\n",
      "Epoch 6/100\n",
      "704/703 [==============================] - 8s 11ms/step - loss: 0.0744 - acc: 0.9853 - auc: 0.5207 - val_loss: 0.1069 - val_acc: 0.9822 - val_auc: 0.5263\n",
      "\n",
      "Epoch 00006: acc did not improve from 0.98729\n",
      "Epoch 7/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0679 - acc: 0.9873 - auc: 0.5304 - val_loss: 0.1039 - val_acc: 0.9822 - val_auc: 0.5308\n",
      "\n",
      "Epoch 00007: acc improved from 0.98729 to 0.98839, saving model to weights-auc\n",
      "Epoch 8/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0874 - acc: 0.9832 - auc: 0.5317 - val_loss: 0.1053 - val_acc: 0.9822 - val_auc: 0.5320\n",
      "\n",
      "Epoch 00008: acc did not improve from 0.98839\n",
      "Epoch 9/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0906 - acc: 0.9827 - auc: 0.5326 - val_loss: 0.1006 - val_acc: 0.9822 - val_auc: 0.5312\n",
      "\n",
      "Epoch 00009: acc did not improve from 0.98839\n",
      "Epoch 10/100\n",
      "704/703 [==============================] - 7s 11ms/step - loss: 0.0732 - acc: 0.9860 - auc: 0.5312 - val_loss: 0.1022 - val_acc: 0.9822 - val_auc: 0.5316\n",
      "\n",
      "Epoch 00010: acc did not improve from 0.98839\n",
      "Epoch 11/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0798 - acc: 0.9856 - auc: 0.5324 - val_loss: 0.1012 - val_acc: 0.9822 - val_auc: 0.5314\n",
      "\n",
      "Epoch 00011: acc did not improve from 0.98839\n",
      "Epoch 12/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0643 - acc: 0.9880 - auc: 0.5332 - val_loss: 0.1016 - val_acc: 0.9822 - val_auc: 0.5333\n",
      "\n",
      "Epoch 00012: acc improved from 0.98839 to 0.98922, saving model to weights-auc\n",
      "Epoch 13/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0786 - acc: 0.9856 - auc: 0.5326 - val_loss: 0.1039 - val_acc: 0.9822 - val_auc: 0.5321\n",
      "\n",
      "Epoch 00013: acc did not improve from 0.98922\n",
      "Epoch 14/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0907 - acc: 0.9824 - auc: 0.5330 - val_loss: 0.1020 - val_acc: 0.9822 - val_auc: 0.5328\n",
      "\n",
      "Epoch 00014: acc did not improve from 0.98922\n",
      "Epoch 15/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0760 - acc: 0.9854 - auc: 0.5328 - val_loss: 0.0973 - val_acc: 0.9822 - val_auc: 0.5332\n",
      "\n",
      "Epoch 00015: acc did not improve from 0.98922\n",
      "Epoch 16/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0812 - acc: 0.9845 - auc: 0.5330 - val_loss: 0.1065 - val_acc: 0.9822 - val_auc: 0.5324\n",
      "\n",
      "Epoch 00016: acc did not improve from 0.98922\n",
      "Epoch 17/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0873 - acc: 0.9831 - auc: 0.5320 - val_loss: 0.0979 - val_acc: 0.9822 - val_auc: 0.5321\n",
      "\n",
      "Epoch 00017: acc did not improve from 0.98922\n"
     ]
    }
   ],
   "source": [
    "hist=model2.fit_generator(generator=generator2(x_train, y_train,batch_size)\n",
    "                    ,steps_per_epoch=x_train.shape[0]/batch_size\n",
    "                    ,epochs=100\n",
    "                    ,validation_data=(x_test,y_test)\n",
    "                    ,callbacks=callbacks_list\n",
    "                    ,shuffle=True\n",
    "                    ,verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 2s 46us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09775600823362668, 0.9822, 0.5222381877581278]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x=x_train,y=y_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model3=load_model(\"model1\",custom_objects={'auc': auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45000/45000 [==============================] - 2s 54us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09775600823362668, 0.9822, 0.5088837131023407]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x=x_train,y=y_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual\t\t|  Pos     |   Neg    |\n",
      "Predicted\t-----------------\n",
      "Pos\t\t| 00000000 | 00000000 |\n",
      "Neg\t\t| 00000801 | 00044199 |\n",
      "\n",
      "Actual\t\t|  Pos     |   Neg    |\n",
      "Predicted\t-----------------\n",
      "Pos\t\t| 00000000 | 00000000 |\n",
      "Neg\t\t| 00000801 | 00044199 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=model2.predict_classes(x=x_train,batch_size=batch_size)\n",
    "confusion_mat(y_train,pred)\n",
    "pred=model3.predict_classes(x=x_train,batch_size=batch_size)\n",
    "confusion_mat(y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 103us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09791486065387726, 0.9822, 0.5399303087234497]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x=x_test,y=y_test,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_col(col,x,x_test,y_test,model):\n",
    "    #global x,x_test,model\n",
    "    x_col=x[:,col]\n",
    "    #mu=np.mean(x_col)\n",
    "    #sigma=np.std(x_col)    \n",
    "    #x[:,col]=np.random.normal(mu,sigma,x_col.shape)\n",
    "    np.random.shuffle(x_col)\n",
    "    x[:,col]=x_col\n",
    "    loss=model.evaluate(x,y_test,verbose=0)[0]\n",
    "    x[:,col]=x_test[:,col]    \n",
    "    return loss\n",
    "    #losses_dict[proc_n]=loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1=model.evaluate(x=x_test,y=y_test,batch_size=batch_size,verbose=0)[0]\n",
    "no_columns=x_test.shape[1]\n",
    "x=x_test.copy()\n",
    "loss_gains1=[]\n",
    "for col in range(len(column_names)):\n",
    "    #col=col+1000\n",
    "    loss=evaluate_col(col,x,x_test,model)\n",
    "    loss_gain=loss/res1\n",
    "    #print(\"col:\",col,\"loss/res:\",loss_gain)\n",
    "    loss_gains1.append([loss_gain,loss_gain-1])\n",
    "\n",
    "loss_gain1=pd.DataFrame(loss_gains1,columns=['loss','delta'],index=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model2.evaluate(x=x_train,y=y_train,batch_size=batch_size,verbose=0)[0]\n",
    "no_columns=x_test.shape[1]\n",
    "x=x_train.copy()\n",
    "loss_gains2=[]\n",
    "for col in range(len(column_names)):\n",
    "    #col=col+1000\n",
    "    loss=evaluate_col(col,x,x_train,y_train,model2)\n",
    "    loss_gain=loss/res\n",
    "    #print(\"col:\",col,\"loss/res:\",loss_gain)\n",
    "    loss_gains2.append([loss_gain,loss_gain-1])\n",
    "    \n",
    "loss_gain3=pd.DataFrame(loss_gains2,columns=['loss','delta'],index=column_names)\n",
    "loss_gain3['ratio']=(loss_gain3['loss']/np.max(loss_gain3['loss'],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>delta</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Var113</th>\n",
       "      <td>1.004799</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var76</th>\n",
       "      <td>1.004783</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.999984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var198</th>\n",
       "      <td>1.002993</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.998203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var94</th>\n",
       "      <td>1.001832</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.997047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var133</th>\n",
       "      <td>1.001797</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.997012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss     delta     ratio\n",
       "Var113  1.004799  0.004799  1.000000\n",
       "Var76   1.004783  0.004783  0.999984\n",
       "Var198  1.002993  0.002993  0.998203\n",
       "Var94   1.001832  0.001832  0.997047\n",
       "Var133  1.001797  0.001797  0.997012"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gain3.sort_values(['ratio'],ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>delta</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Var162</th>\n",
       "      <td>1.025390</td>\n",
       "      <td>0.025390</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var124</th>\n",
       "      <td>1.011540</td>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.986493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var134</th>\n",
       "      <td>1.004572</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.979698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var163</th>\n",
       "      <td>1.003806</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.978950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var76</th>\n",
       "      <td>1.002900</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.978067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var153</th>\n",
       "      <td>1.001546</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.976746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var177</th>\n",
       "      <td>1.001128</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.976339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var150</th>\n",
       "      <td>1.001088</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var214</th>\n",
       "      <td>1.000936</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.976152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var192</th>\n",
       "      <td>1.000917</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>0.976133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var216</th>\n",
       "      <td>1.000894</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.976111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var86</th>\n",
       "      <td>1.000833</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.976051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var16</th>\n",
       "      <td>1.000769</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.975988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var200</th>\n",
       "      <td>1.000748</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.975968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var51</th>\n",
       "      <td>1.000559</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.975783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var171</th>\n",
       "      <td>1.000462</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.975690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var108</th>\n",
       "      <td>1.000453</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.975680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var70</th>\n",
       "      <td>1.000414</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.975642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var58</th>\n",
       "      <td>1.000383</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.975613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var227</th>\n",
       "      <td>1.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.975534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss     delta     ratio\n",
       "Var162  1.025390  0.025390  1.000000\n",
       "Var124  1.011540  0.011540  0.986493\n",
       "Var134  1.004572  0.004572  0.979698\n",
       "Var163  1.003806  0.003806  0.978950\n",
       "Var76   1.002900  0.002900  0.978067\n",
       "Var153  1.001546  0.001546  0.976746\n",
       "Var177  1.001128  0.001128  0.976339\n",
       "Var150  1.001088  0.001088  0.976300\n",
       "Var214  1.000936  0.000936  0.976152\n",
       "Var192  1.000917  0.000917  0.976133\n",
       "Var216  1.000894  0.000894  0.976111\n",
       "Var86   1.000833  0.000833  0.976051\n",
       "Var16   1.000769  0.000769  0.975988\n",
       "Var200  1.000748  0.000748  0.975968\n",
       "Var51   1.000559  0.000559  0.975783\n",
       "Var171  1.000462  0.000462  0.975690\n",
       "Var108  1.000453  0.000453  0.975680\n",
       "Var70   1.000414  0.000414  0.975642\n",
       "Var58   1.000383  0.000383  0.975613\n",
       "Var227  1.000303  0.000303  0.975534"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gain2.sort_values(['ratio'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Var118</th>\n",
       "      <td>1.013408</td>\n",
       "      <td>0.013408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var56</th>\n",
       "      <td>0.990226</td>\n",
       "      <td>0.009774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var46</th>\n",
       "      <td>0.991621</td>\n",
       "      <td>0.008379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var74</th>\n",
       "      <td>0.991960</td>\n",
       "      <td>0.008040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var9</th>\n",
       "      <td>1.007326</td>\n",
       "      <td>0.007326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var217</th>\n",
       "      <td>0.992894</td>\n",
       "      <td>0.007106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var165</th>\n",
       "      <td>1.005965</td>\n",
       "      <td>0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var35</th>\n",
       "      <td>0.994079</td>\n",
       "      <td>0.005921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var128</th>\n",
       "      <td>1.005786</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var51</th>\n",
       "      <td>0.995246</td>\n",
       "      <td>0.004754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var132</th>\n",
       "      <td>0.996307</td>\n",
       "      <td>0.003693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var13</th>\n",
       "      <td>1.003509</td>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var105</th>\n",
       "      <td>0.996560</td>\n",
       "      <td>0.003440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var103</th>\n",
       "      <td>0.996576</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var140</th>\n",
       "      <td>1.003363</td>\n",
       "      <td>0.003363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var69</th>\n",
       "      <td>0.996724</td>\n",
       "      <td>0.003276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var7</th>\n",
       "      <td>0.996727</td>\n",
       "      <td>0.003273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var155</th>\n",
       "      <td>1.003241</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var54</th>\n",
       "      <td>1.003192</td>\n",
       "      <td>0.003192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var124</th>\n",
       "      <td>1.003093</td>\n",
       "      <td>0.003093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss     delta\n",
       "Var118  1.013408  0.013408\n",
       "Var56   0.990226  0.009774\n",
       "Var46   0.991621  0.008379\n",
       "Var74   0.991960  0.008040\n",
       "Var9    1.007326  0.007326\n",
       "Var217  0.992894  0.007106\n",
       "Var165  1.005965  0.005965\n",
       "Var35   0.994079  0.005921\n",
       "Var128  1.005786  0.005786\n",
       "Var51   0.995246  0.004754\n",
       "Var132  0.996307  0.003693\n",
       "Var13   1.003509  0.003509\n",
       "Var105  0.996560  0.003440\n",
       "Var103  0.996576  0.003424\n",
       "Var140  1.003363  0.003363\n",
       "Var69   0.996724  0.003276\n",
       "Var7    0.996727  0.003273\n",
       "Var155  1.003241  0.003241\n",
       "Var54   1.003192  0.003192\n",
       "Var124  1.003093  0.003093"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(loss_gain2)).sort_values(['delta'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns=loss_gain2.loc[(loss_gain2.loss < 1.0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cols=(np.abs(loss_gain2)).sort_values(['delta'],ascending=False).head(50)\n",
    "selected_columns=_cols.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_column_id=[]\n",
    "_=[selected_column_id.append(column_names.index(col)) for col in selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_unit=16,input_feature_num=x_train.shape[1]):\n",
    "\n",
    "    #input_feature_num=x_train.shape[1]\n",
    "    \n",
    "    model = Sequential(name=\"kdd2009\")\n",
    "    \n",
    "    \n",
    "    model.add(layers.BatchNormalization(name=\"Input_Norm\", input_shape=(input_feature_num,)))\n",
    "    #model.add(layers.Dropout(.7))\n",
    "    #model.add(layers)\n",
    "    \n",
    "    model.add(layers.Dense(name='hidden_l1', units=hidden_unit))\n",
    "    #model.add(layers.Dropout(.7))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dense(name='hidden_l2', units=hidden_unit))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    \n",
    "    model.add(layers.Dense(name='output', units=1))\n",
    "    model.add(layers.Activation('sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "#model2 = None\n",
    "model3 = create_model(input_feature_num=len(selected_column_id))\n",
    "model3.compile(optimizer='adam',loss=losses.binary_crossentropy, metrics=['acc',auc])\n",
    "filepath=\"weights-auc-{epoch:02d}-{loss:.4f}\"\n",
    "earlystop=EarlyStopping(monitor='val_auc', min_delta=1e-3, patience=5, verbose=0, mode='max')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_auc', verbose=1, save_best_only=True, mode='max',save_weights_only=True)\n",
    "callbacks_list = [earlystop,PostOpt(x_train,y_train,x_test[:,selected_column_id],y_test),checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "704/703 [==============================] - 9s 13ms/step - loss: 0.1190 - acc: 0.9753 - auc: 0.4899 - val_loss: 0.1159 - val_acc: 0.9776 - val_auc: 0.5012\n",
      "0 [0.4976583]\n",
      "\n",
      "Epoch 00001: val_auc improved from -inf to 0.50123, saving model to weights-auc-01-0.1199\n",
      "Epoch 2/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0868 - acc: 0.9830 - auc: 0.5220 - val_loss: 0.1217 - val_acc: 0.9764 - val_auc: 0.5115\n",
      "0 [0.49704745]\n",
      "\n",
      "Epoch 00002: val_auc improved from 0.50123 to 0.51147, saving model to weights-auc-02-0.0830\n",
      "Epoch 3/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0703 - acc: 0.9869 - auc: 0.5244 - val_loss: 0.1172 - val_acc: 0.9792 - val_auc: 0.5207\n",
      "0 [0.4984728]\n",
      "\n",
      "Epoch 00003: val_auc improved from 0.51147 to 0.52067, saving model to weights-auc-03-0.0667\n",
      "Epoch 4/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0684 - acc: 0.9875 - auc: 0.5240 - val_loss: 0.1159 - val_acc: 0.9796 - val_auc: 0.5223\n",
      "0 [0.49867645]\n",
      "\n",
      "Epoch 00004: val_auc improved from 0.52067 to 0.52233, saving model to weights-auc-04-0.0675\n",
      "Epoch 5/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0831 - acc: 0.9841 - auc: 0.5265 - val_loss: 0.1169 - val_acc: 0.9772 - val_auc: 0.5234\n",
      "0 [0.4974547]\n",
      "\n",
      "Epoch 00005: val_auc improved from 0.52233 to 0.52341, saving model to weights-auc-05-0.0782\n",
      "Epoch 6/100\n",
      "704/703 [==============================] - 7s 9ms/step - loss: 0.0851 - acc: 0.9834 - auc: 0.5251 - val_loss: 0.1073 - val_acc: 0.9786 - val_auc: 0.5232\n",
      "0 [0.49816737]\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.52341\n",
      "Epoch 7/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0862 - acc: 0.9826 - auc: 0.5257 - val_loss: 0.1201 - val_acc: 0.9802 - val_auc: 0.5275\n",
      "0 [0.49898186]\n",
      "\n",
      "Epoch 00007: val_auc improved from 0.52341 to 0.52748, saving model to weights-auc-07-0.0834\n",
      "Epoch 8/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0831 - acc: 0.9840 - auc: 0.5296 - val_loss: 0.1157 - val_acc: 0.9800 - val_auc: 0.5277\n",
      "0 [0.49888006]\n",
      "\n",
      "Epoch 00008: val_auc improved from 0.52748 to 0.52766, saving model to weights-auc-08-0.0801\n",
      "Epoch 9/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0741 - acc: 0.9854 - auc: 0.5302 - val_loss: 0.1164 - val_acc: 0.9788 - val_auc: 0.5298\n",
      "0 [0.4982692]\n",
      "\n",
      "Epoch 00009: val_auc improved from 0.52766 to 0.52984, saving model to weights-auc-09-0.0695\n",
      "Epoch 10/100\n",
      "704/703 [==============================] - 7s 9ms/step - loss: 0.0682 - acc: 0.9871 - auc: 0.5319 - val_loss: 0.1169 - val_acc: 0.9810 - val_auc: 0.5310\n",
      "0 [0.4993891]\n",
      "\n",
      "Epoch 00010: val_auc improved from 0.52984 to 0.53098, saving model to weights-auc-10-0.0655\n",
      "Epoch 11/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0794 - acc: 0.9847 - auc: 0.5322 - val_loss: 0.1112 - val_acc: 0.9790 - val_auc: 0.5309\n",
      "0 [0.498371]\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.53098\n",
      "Epoch 12/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0614 - acc: 0.9888 - auc: 0.5322 - val_loss: 0.1078 - val_acc: 0.9798 - val_auc: 0.5310\n",
      "0 [0.49877825]\n",
      "\n",
      "Epoch 00012: val_auc did not improve from 0.53098\n",
      "Epoch 13/100\n",
      "704/703 [==============================] - 6s 9ms/step - loss: 0.0658 - acc: 0.9883 - auc: 0.5294 - val_loss: 0.1106 - val_acc: 0.9792 - val_auc: 0.5278\n",
      "0 [0.4984728]\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.53098\n",
      "Epoch 14/100\n",
      "704/703 [==============================] - 7s 10ms/step - loss: 0.0777 - acc: 0.9852 - auc: 0.5274 - val_loss: 0.1253 - val_acc: 0.9790 - val_auc: 0.5261\n",
      "0 [0.498371]\n",
      "\n",
      "Epoch 00014: val_auc did not improve from 0.53098\n",
      "Epoch 15/100\n",
      "704/703 [==============================] - 7s 9ms/step - loss: 0.0751 - acc: 0.9858 - auc: 0.5256 - val_loss: 0.1211 - val_acc: 0.9798 - val_auc: 0.5249\n",
      "0 [0.49877825]\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.53098\n"
     ]
    }
   ],
   "source": [
    "hist=model3.fit_generator(generator=generator2(x_train[:,selected_column_id], y_train,batch_size)\n",
    "                    ,steps_per_epoch=x_train.shape[0]/batch_size\n",
    "                    ,epochs=100\n",
    "                    ,validation_data=(x_test[:,selected_column_id],y_test)\n",
    "                    ,callbacks=callbacks_list\n",
    "                    ,shuffle=True\n",
    "                    ,verbose=1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=model3.evaluate(x=x_test[:,selected_column_id],y=y_test,batch_size=batch_size,verbose=0)[0]\n",
    "no_columns=x_test.shape[1]\n",
    "x=x_test[:,selected_column_id].copy()\n",
    "loss_gains3=[]\n",
    "for col in range(len(selected_columns)):\n",
    "    #col=col+1000\n",
    "    loss=evaluate_col(col,x,x_test[:,selected_column_id],model3)\n",
    "    loss_gain=loss/res\n",
    "    #print(\"col:\",col,\"loss/res:\",loss_gain)\n",
    "    loss_gains3.append([loss_gain,loss_gain-1])\n",
    "    \n",
    "loss_gain3=pd.DataFrame(loss_gains3,columns=['loss','delta'],index=selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4899,   12],\n",
       "       [  89,    0]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=model3.predict_classes(x=x_test[:,selected_column_id],batch_size=batch_size)\n",
    "mat=confusion_matrix(y_test,pred)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive: 0\n",
      "false positive: 12\n",
      "true negative; 4899\n",
      "false negative 89\n"
     ]
    }
   ],
   "source": [
    "true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_test,pred).ravel()\n",
    "print('true positive:',true_positive)\n",
    "print('false positive:',false_positive)\n",
    "print('true negative;',true_negative)\n",
    "print('false negative',false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def confusion_mat(y_test,y_pred):\n",
    "    true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_test,y_pred).ravel()\n",
    "    print(\"Actual\\t\\t|  Pos     |   Neg    |\")\n",
    "    print(\"Predicted\\t-----------------\")\n",
    "    print(\"Pos\\t\\t| {0:08d} | {1:08d} |\".format(true_positive,false_positive))\n",
    "    print(\"Neg\\t\\t| {0:08d} | {1:08d} |\\n\".format(false_negative,true_negative))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual\t\t|  Pos     |   Neg    |\n",
      "Predicted\t-----------------\n",
      "Pos\t\t| 00000004 | 00000136 |\n",
      "Neg\t\t| 00000797 | 00044063 |\n",
      "\n",
      "Actual\t\t|  Pos     |   Neg    |\n",
      "Predicted\t-----------------\n",
      "Pos\t\t| 00000000 | 00000001 |\n",
      "Neg\t\t| 00000801 | 00044198 |\n",
      "\n",
      "Actual\t\t|  Pos     |   Neg    |\n",
      "Predicted\t-----------------\n",
      "Pos\t\t| 00000000 | 00000000 |\n",
      "Neg\t\t| 00000801 | 00044199 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=model3.predict_classes(x=x_train[:,selected_column_id],batch_size=batch_size)\n",
    "confusion_mat(y_train,pred)\n",
    "pred=model2.predict_classes(x=x_train,batch_size=batch_size)\n",
    "confusion_mat(y_train,pred)\n",
    "pred=model.predict_classes(x=x_train,batch_size=batch_size)\n",
    "confusion_mat(y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Var68</th>\n",
       "      <td>1.118528</td>\n",
       "      <td>0.118528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var46</th>\n",
       "      <td>1.086111</td>\n",
       "      <td>0.086111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var105</th>\n",
       "      <td>1.077477</td>\n",
       "      <td>0.077477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var92</th>\n",
       "      <td>1.065804</td>\n",
       "      <td>0.065804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var11</th>\n",
       "      <td>1.040183</td>\n",
       "      <td>0.040183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var188</th>\n",
       "      <td>1.036347</td>\n",
       "      <td>0.036347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var103</th>\n",
       "      <td>1.034272</td>\n",
       "      <td>0.034272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var84</th>\n",
       "      <td>1.029994</td>\n",
       "      <td>0.029994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var45</th>\n",
       "      <td>1.026106</td>\n",
       "      <td>0.026106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var56</th>\n",
       "      <td>1.025040</td>\n",
       "      <td>0.025040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var19</th>\n",
       "      <td>1.022326</td>\n",
       "      <td>0.022326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var176</th>\n",
       "      <td>1.019924</td>\n",
       "      <td>0.019924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var114</th>\n",
       "      <td>1.015574</td>\n",
       "      <td>0.015574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var3</th>\n",
       "      <td>1.010740</td>\n",
       "      <td>0.010740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var130</th>\n",
       "      <td>1.010408</td>\n",
       "      <td>0.010408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var81</th>\n",
       "      <td>1.009892</td>\n",
       "      <td>0.009892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var164</th>\n",
       "      <td>1.006630</td>\n",
       "      <td>0.006630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var10</th>\n",
       "      <td>1.005990</td>\n",
       "      <td>0.005990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var190</th>\n",
       "      <td>1.005606</td>\n",
       "      <td>0.005606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var110</th>\n",
       "      <td>1.004911</td>\n",
       "      <td>0.004911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss     delta\n",
       "Var68   1.118528  0.118528\n",
       "Var46   1.086111  0.086111\n",
       "Var105  1.077477  0.077477\n",
       "Var92   1.065804  0.065804\n",
       "Var11   1.040183  0.040183\n",
       "Var188  1.036347  0.036347\n",
       "Var103  1.034272  0.034272\n",
       "Var84   1.029994  0.029994\n",
       "Var45   1.026106  0.026106\n",
       "Var56   1.025040  0.025040\n",
       "Var19   1.022326  0.022326\n",
       "Var176  1.019924  0.019924\n",
       "Var114  1.015574  0.015574\n",
       "Var3    1.010740  0.010740\n",
       "Var130  1.010408  0.010408\n",
       "Var81   1.009892  0.009892\n",
       "Var164  1.006630  0.006630\n",
       "Var10   1.005990  0.005990\n",
       "Var190  1.005606  0.005606\n",
       "Var110  1.004911  0.004911"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gain3.sort_values(['loss'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Var62</th>\n",
       "      <td>1.024996</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var99</th>\n",
       "      <td>1.011205</td>\n",
       "      <td>0.011205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var34</th>\n",
       "      <td>1.008103</td>\n",
       "      <td>0.008103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var166</th>\n",
       "      <td>1.006981</td>\n",
       "      <td>0.006981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var111</th>\n",
       "      <td>1.005699</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var158</th>\n",
       "      <td>1.005058</td>\n",
       "      <td>0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var118</th>\n",
       "      <td>1.004223</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var135</th>\n",
       "      <td>1.004218</td>\n",
       "      <td>0.004218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var41</th>\n",
       "      <td>1.004051</td>\n",
       "      <td>0.004051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var197</th>\n",
       "      <td>1.003540</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var66</th>\n",
       "      <td>1.003181</td>\n",
       "      <td>0.003181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var17</th>\n",
       "      <td>1.003039</td>\n",
       "      <td>0.003039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var108</th>\n",
       "      <td>1.002998</td>\n",
       "      <td>0.002998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var159</th>\n",
       "      <td>1.002759</td>\n",
       "      <td>0.002759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var83</th>\n",
       "      <td>1.002662</td>\n",
       "      <td>0.002662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var129</th>\n",
       "      <td>1.001877</td>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var189</th>\n",
       "      <td>1.001800</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var170</th>\n",
       "      <td>1.001722</td>\n",
       "      <td>0.001722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var206</th>\n",
       "      <td>1.001520</td>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var150</th>\n",
       "      <td>1.001422</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss     delta\n",
       "Var62   1.024996  0.024996\n",
       "Var99   1.011205  0.011205\n",
       "Var34   1.008103  0.008103\n",
       "Var166  1.006981  0.006981\n",
       "Var111  1.005699  0.005699\n",
       "Var158  1.005058  0.005058\n",
       "Var118  1.004223  0.004223\n",
       "Var135  1.004218  0.004218\n",
       "Var41   1.004051  0.004051\n",
       "Var197  1.003540  0.003540\n",
       "Var66   1.003181  0.003181\n",
       "Var17   1.003039  0.003039\n",
       "Var108  1.002998  0.002998\n",
       "Var159  1.002759  0.002759\n",
       "Var83   1.002662  0.002662\n",
       "Var129  1.001877  0.001877\n",
       "Var189  1.001800  0.001800\n",
       "Var170  1.001722  0.001722\n",
       "Var206  1.001520  0.001520\n",
       "Var150  1.001422  0.001422"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gain3.sort_values(['loss'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Var118</th>\n",
       "      <td>1.013408</td>\n",
       "      <td>-0.013408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var9</th>\n",
       "      <td>1.007326</td>\n",
       "      <td>-0.007326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var165</th>\n",
       "      <td>1.005965</td>\n",
       "      <td>-0.005965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var128</th>\n",
       "      <td>1.005786</td>\n",
       "      <td>-0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var13</th>\n",
       "      <td>1.003509</td>\n",
       "      <td>-0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var140</th>\n",
       "      <td>1.003363</td>\n",
       "      <td>-0.003363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var155</th>\n",
       "      <td>1.003241</td>\n",
       "      <td>-0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var54</th>\n",
       "      <td>1.003192</td>\n",
       "      <td>-0.003192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var124</th>\n",
       "      <td>1.003093</td>\n",
       "      <td>-0.003093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var147</th>\n",
       "      <td>1.002979</td>\n",
       "      <td>-0.002979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var149</th>\n",
       "      <td>1.002826</td>\n",
       "      <td>-0.002826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var129</th>\n",
       "      <td>1.002551</td>\n",
       "      <td>-0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var44</th>\n",
       "      <td>1.002414</td>\n",
       "      <td>-0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var117</th>\n",
       "      <td>1.002001</td>\n",
       "      <td>-0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var126</th>\n",
       "      <td>1.001777</td>\n",
       "      <td>-0.001777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var120</th>\n",
       "      <td>1.001703</td>\n",
       "      <td>-0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var14</th>\n",
       "      <td>1.001669</td>\n",
       "      <td>-0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var198</th>\n",
       "      <td>1.001490</td>\n",
       "      <td>-0.001490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var144</th>\n",
       "      <td>1.001432</td>\n",
       "      <td>-0.001432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var65</th>\n",
       "      <td>1.001244</td>\n",
       "      <td>-0.001244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss     delta\n",
       "Var118  1.013408 -0.013408\n",
       "Var9    1.007326 -0.007326\n",
       "Var165  1.005965 -0.005965\n",
       "Var128  1.005786 -0.005786\n",
       "Var13   1.003509 -0.003509\n",
       "Var140  1.003363 -0.003363\n",
       "Var155  1.003241 -0.003241\n",
       "Var54   1.003192 -0.003192\n",
       "Var124  1.003093 -0.003093\n",
       "Var147  1.002979 -0.002979\n",
       "Var149  1.002826 -0.002826\n",
       "Var129  1.002551 -0.002551\n",
       "Var44   1.002414 -0.002414\n",
       "Var117  1.002001 -0.002001\n",
       "Var126  1.001777 -0.001777\n",
       "Var120  1.001703 -0.001703\n",
       "Var14   1.001669 -0.001669\n",
       "Var198  1.001490 -0.001490\n",
       "Var144  1.001432 -0.001432\n",
       "Var65   1.001244 -0.001244"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_gain2.sort_values(['loss'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns3=loss_gain3.loc[(loss_gain3.loss < 1.0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Var2', 'Var8', 'Var13', 'Var14', 'Var15', 'Var20', 'Var23', 'Var24',\n",
       "       'Var26', 'Var28',\n",
       "       ...\n",
       "       'Var165_imputed', 'Var167_imputed', 'Var169_imputed', 'Var175_imputed',\n",
       "       'Var178_imputed', 'Var179_imputed', 'Var183_imputed', 'Var185_imputed',\n",
       "       'Var209_imputed', 'Var230_imputed'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu3",
   "language": "python",
   "name": "tensorflow-gpu3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
